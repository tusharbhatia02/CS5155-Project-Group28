{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0d4e9698a194539bcc18791ad183a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_402819eabfe746a4b867ebcdd8ca5f33",
              "IPY_MODEL_eff65fd586004a86b247c23066cc6ca6",
              "IPY_MODEL_d68da84a89fc44d884d6893ab2038e06"
            ],
            "layout": "IPY_MODEL_68c6cf0b18f84b0b943b45c72d28569e"
          }
        },
        "402819eabfe746a4b867ebcdd8ca5f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd62dadbef4613a9139cc960c64cee",
            "placeholder": "​",
            "style": "IPY_MODEL_c3441f7b4efe4cdf92691f10709e508e",
            "value": "model.safetensors: 100%"
          }
        },
        "eff65fd586004a86b247c23066cc6ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd422543e1e44f4a9a9612f46281421",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f7f9a8cf0184912a24f564631a78b02",
            "value": 267954768
          }
        },
        "d68da84a89fc44d884d6893ab2038e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3f3585496d4e3c95a7c6ca1576ad8c",
            "placeholder": "​",
            "style": "IPY_MODEL_84462cc500464f48a282c6a29c609d8d",
            "value": " 268M/268M [00:02&lt;00:00, 129MB/s]"
          }
        },
        "68c6cf0b18f84b0b943b45c72d28569e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cd62dadbef4613a9139cc960c64cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3441f7b4efe4cdf92691f10709e508e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd422543e1e44f4a9a9612f46281421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7f9a8cf0184912a24f564631a78b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd3f3585496d4e3c95a7c6ca1576ad8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84462cc500464f48a282c6a29c609d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx9a1KmP5L84",
        "outputId": "10a33fa6-d8b8-42d9-bfad-c9aa2a5a02c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers tqdm scikit-learn pillow ijson pandas gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import json\n",
        "import ijson\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Define Configuration\n",
        "\n",
        "# Set Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device set to: {device}\")\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the ZIP file in Drive containing 50,000 images\n",
        "ZIP_FILE_PATH = \"/content/drive/MyDrive/recipe_project/recipe1m_tiny_50k.zip\"\n",
        "\n",
        "# Paths to the JSON files in Drive\n",
        "LAYER1_JSON = \"/content/drive/MyDrive/recipe_project/layer1.json\"  # Text\n",
        "LAYER2_JSON = \"/content/drive/MyDrive/recipe_project/layer2+.json\"  # Images\n",
        "\n",
        "# Local Runtime Paths\n",
        "PROJECT_ROOT = \"/content/recipe_project_50k\"\n",
        "IMAGES_DIR = f\"{PROJECT_ROOT}/images\"\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Configuration complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYUtPHsz5bH0",
        "outputId": "d15bc626-c413-49c9-cd68-41b7e5348b47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to: cuda\n",
            "Mounted at /content/drive\n",
            "Configuration complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "DS_Hfy9EiwYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unzip_data(zip_path, extract_to):\n",
        "\n",
        "    # Check if unzipped file exists\n",
        "    if len(os.listdir(extract_to)) > 100:\n",
        "        print(f\"Folder {extract_to} already has files. Skipping unzip.\")\n",
        "        return\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Filter to extract only JPGs if zip is messy\n",
        "        for file in tqdm(zip_ref.namelist(), desc=\"Extracting\"):\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                zip_ref.extract(file, extract_to)\n",
        "\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "# Run the extraction\n",
        "unzip_data(ZIP_FILE_PATH, IMAGES_DIR)\n",
        "\n",
        "# Handle nested folders\n",
        "contents = [f for f in os.listdir(IMAGES_DIR) if not f.startswith('__MACOSX')]\n",
        "\n",
        "if len(contents) == 1 and os.path.isdir(os.path.join(IMAGES_DIR, contents[0])):\n",
        "    FINAL_IMG_DIR = os.path.join(IMAGES_DIR, contents[0])\n",
        "else:\n",
        "    FINAL_IMG_DIR = IMAGES_DIR\n",
        "\n",
        "print(f\"Images are located in: {FINAL_IMG_DIR}\")\n",
        "print(f\"Image Count: {len([f for f in os.listdir(FINAL_IMG_DIR) if f.endswith('.jpg')])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd666slZ5tqw",
        "outputId": "69a7d57c-4476-43b5-b724-63d5a9cb772a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|██████████| 50002/50002 [03:43<00:00, 223.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n",
            "Images are located in: /content/recipe_project_50k/images/recipe1m_tiny_50k\n",
            "Image Count: 50000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get set of available image filenames on disk\n",
        "available_images = set(os.listdir(FINAL_IMG_DIR))\n",
        "print(f\"Found {len(available_images)} images on disk.\")\n",
        "\n",
        "# 1. Map Image Filename -> Recipe ID (using layer2.json)\n",
        "matched_recipe_ids = set()\n",
        "id_to_img = {}\n",
        "\n",
        "print(\"Streaming layer2+.json to match images\")\n",
        "with open(LAYER2_JSON, 'rb') as f:\n",
        "\n",
        "    for entry in ijson.items(f, 'item'):\n",
        "        rid = entry['id']\n",
        "        for img in entry.get('images', []):\n",
        "            fname = img['id']\n",
        "            # If this image exists in our 12k folder\n",
        "            if fname in available_images:\n",
        "                matched_recipe_ids.add(rid)\n",
        "                id_to_img[rid] = fname\n",
        "                break\n",
        "\n",
        "print(f\"Matched {len(matched_recipe_ids)} Recipe IDs.\")\n",
        "\n",
        "# 2. Extract Text for those IDs (using layer1.json)\n",
        "final_dataset = []\n",
        "\n",
        "print(\"Streaming layer1.json to extract text\")\n",
        "with open(LAYER1_JSON, 'rb') as f:\n",
        "    for entry in ijson.items(f, 'item'):\n",
        "        rid = entry['id']\n",
        "        if rid in matched_recipe_ids:\n",
        "            final_dataset.append({\n",
        "                \"recipe_id\": rid,\n",
        "                \"image_filename\": id_to_img[rid],\n",
        "                \"title\": entry.get(\"title\", \"Untitled\"),\n",
        "                \"ingredients\": [x['text'] for x in entry.get(\"ingredients\", [])],\n",
        "                \"instructions\": [x['text'] for x in entry.get(\"instructions\", [])]\n",
        "            })\n",
        "\n",
        "print(f\"Final Dataset Size: {len(final_dataset)} pairs.\")\n",
        "\n",
        "# Save this cleaned dataset\n",
        "with open(f\"{PROJECT_ROOT}/dataset_50k_clean.json\", \"w\") as f:\n",
        "    json.dump(final_dataset, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mULJ1HEn56GL",
        "outputId": "748e017a-11a8-4754-9e04-8290f01a2535"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50000 images on disk.\n",
            "Streaming layer2+.json to match images\n",
            "Matched 23127 Recipe IDs.\n",
            "Streaming layer1.json to extract text\n",
            "Final Dataset Size: 23127 pairs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "rTpNG2msjdxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A. AUGMENTATION (The Fix for Overfitting)\n",
        "# We use strong augmentation for training to force the model to learn features, not pixels.\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),        # Resize slightly larger than target\n",
        "    transforms.RandomCrop(224),           # Randomly crop the 224x224 area\n",
        "    transforms.RandomHorizontalFlip(),    # Flip left/right (food looks same flipped)\n",
        "    transforms.RandomRotation(15),        # Rotate +/- 15 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Vary lighting\n",
        "    transforms.ToTensor(),                # Convert to Tensor\n",
        "    transforms.Normalize(                 # Normalize to ImageNet standards\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# For Validation, resize and normalize (No randomness)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "# B. DATASET CLASS\n",
        "\n",
        "class RecipeDataset(Dataset):\n",
        "    def __init__(self, data_list, img_dir, transform, tokenizer, max_len=128):\n",
        "        self.data = data_list\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        # 1. Image\n",
        "        img_path = os.path.join(self.img_dir, item['image_filename'])\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            image = self.transform(image)\n",
        "        except:\n",
        "            # Fallback for corrupted images\n",
        "            image = torch.zeros(3, 224, 224)\n",
        "\n",
        "        # 2. Text (Concatenate Title + Ingredients + Instructions)\n",
        "        # We join them to give BERT maximum context\n",
        "        text_input = f\"{item['title']} [SEP] \" + \\\n",
        "                     \" \".join(item['ingredients']) + \\\n",
        "                     \" [SEP] \" + \\\n",
        "                     \" \".join(item['instructions'])\n",
        "\n",
        "        encoded = self.tokenizer(\n",
        "            text_input,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"input_ids\": encoded['input_ids'].squeeze(0),\n",
        "            \"attention_mask\": encoded['attention_mask'].squeeze(0),\n",
        "            \"recipe_id\": item['recipe_id'] # Keep ID for lookup later\n",
        "        }\n",
        "\n",
        "print(\"Transforms and Dataset class defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdN-0ORI6qAv",
        "outputId": "2289ed99-9444-47b8-e450-81c4c83ab37a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforms and Dataset class defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "nexuMPC4jqrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. LOAD CLEAN DATASET (100k)\n",
        "\n",
        "DATASET_PATH = f\"{PROJECT_ROOT}/dataset_50k_clean.json\"\n",
        "\n",
        "with open(DATASET_PATH, \"r\") as f:\n",
        "    full_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(full_data)} (image, text) pairs from {DATASET_PATH}\")\n",
        "\n",
        "\n",
        "# 2. 3-WAY SPLIT: Train (80%), Validation (10%), Test (10%)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# To Ensure reproducibility\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Shuffle entire dataset once\n",
        "np.random.seed(RANDOM_SEED)\n",
        "np.random.shuffle(full_data)\n",
        "\n",
        "# Train / Temp split (80% / 20%)\n",
        "train_list, temp_list = train_test_split(\n",
        "    full_data,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Temp → Val/Test split (50% / 50% of the 20%)\n",
        "val_list, test_list = train_test_split(\n",
        "    temp_list,\n",
        "    test_size=0.50,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(\"Dataset Splits:\")\n",
        "print(f\" Train      : {len(train_list)} ({len(train_list)/len(full_data)*100:.1f}%)\")\n",
        "print(f\" Validation : {len(val_list)} ({len(val_list)/len(full_data)*100:.1f}%)\")\n",
        "print(f\" Test       : {len(test_list)} ({len(test_list)/len(full_data)*100:.1f}%)\")\n",
        "\n",
        "\n",
        "\n",
        "# 3. TOKENIZER (DistilBERT)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    model_max_length=128,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "print(\"Tokenizer initialized.\")\n",
        "\n",
        "\n",
        "\n",
        "# 4. DATASETS\n",
        "\n",
        "train_dataset = RecipeDataset(\n",
        "    train_list, FINAL_IMG_DIR, train_transform, tokenizer\n",
        ")\n",
        "val_dataset = RecipeDataset(\n",
        "    val_list, FINAL_IMG_DIR, val_transform, tokenizer\n",
        ")\n",
        "test_dataset = RecipeDataset(\n",
        "    test_list, FINAL_IMG_DIR, val_transform, tokenizer\n",
        ")\n",
        "\n",
        "print(\"Datasets constructed.\")\n",
        "\n",
        "\n",
        "# 5. DATA LOADERS\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"DataLoaders ready (batch_size={BATCH_SIZE}).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mX53sCG8Qge",
        "outputId": "0102a61e-a7ca-4c1c-ceff-8d5c378f67d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 23127 (image, text) pairs from /content/recipe_project_50k/dataset_50k_clean.json\n",
            "Dataset Splits:\n",
            " Train      : 18501 (80.0%)\n",
            " Validation : 2313 (10.0%)\n",
            " Test       : 2313 (10.0%)\n",
            "Tokenizer initialized.\n",
            "Datasets constructed.\n",
            "DataLoaders ready (batch_size=32).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# DUAL ENCODER\n",
        "# ---------------------------------------------------------\n",
        "class DualEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim=256, freeze_cnn=True, freeze_text_epochs=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.freeze_text_epochs = freeze_text_epochs\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # IMAGE ENCODER (RESNET50)\n",
        "        # ---------------------------------------------------------\n",
        "        self.cnn = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, embed_dim)\n",
        "\n",
        "        # Freeze CNN initially\n",
        "        if freeze_cnn:\n",
        "            for p in self.cnn.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in self.cnn.fc.parameters():\n",
        "                p.requires_grad = True\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # TEXT ENCODER (DISTILBERT)\n",
        "        # ---------------------------------------------------------\n",
        "        self.text_encoder = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.text_proj = nn.Linear(768, embed_dim)\n",
        "\n",
        "        # Freeze text encoder initially\n",
        "        for p in self.text_encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def unfreeze_text_encoder(self):\n",
        "        print(\"Unfreezing Text Encoder…\")\n",
        "        for p in self.text_encoder.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    def forward(self, images=None, input_ids=None, attention_mask=None):\n",
        "        img_features = None\n",
        "        txt_features = None\n",
        "\n",
        "        if images is not None:\n",
        "            img_features = self.cnn(images)\n",
        "            img_features = F.normalize(img_features, p=2, dim=1)\n",
        "\n",
        "        if input_ids is not None:\n",
        "            txt_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            txt_features = txt_out.last_hidden_state[:, 0, :]\n",
        "            txt_features = self.text_proj(txt_features)\n",
        "            txt_features = F.normalize(txt_features, p=2, dim=1)\n",
        "\n",
        "        return img_features, txt_features\n"
      ],
      "metadata": {
        "id": "t6NUrHuT8U3s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# TRAINING FUNCTION\n",
        "# ---------------------------------------------------------\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=20,\n",
        "    lr=1e-4,\n",
        "    patience=4,\n",
        "    unfreeze_cnn_epoch=3,\n",
        "    temperature=0.07,\n",
        "    save_path=f\"{PROJECT_ROOT}/best_model.pt\"\n",
        "):\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=epochs,\n",
        "        eta_min=lr * 0.1\n",
        "    )\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    def contrastive_loss(img_emb, txt_emb, temperature=temperature):\n",
        "        logits = (img_emb @ txt_emb.T) / temperature\n",
        "        logits = torch.clamp(logits, -50, 50)\n",
        "\n",
        "        labels = torch.arange(len(logits)).to(device)\n",
        "        loss_i = nn.CrossEntropyLoss()(logits, labels)\n",
        "        loss_t = nn.CrossEntropyLoss()(logits.T, labels)\n",
        "\n",
        "        return (loss_i + loss_t) / 2\n",
        "\n",
        "    print(\"Starting Training...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Unfreeze text encoder AFTER warmup\n",
        "        if epoch == model.freeze_text_epochs:\n",
        "            model.unfreeze_text_encoder()\n",
        "\n",
        "        # Unfreeze CNN later\n",
        "        if epoch == unfreeze_cnn_epoch:\n",
        "            print(f\"Unfreezing CNN at epoch {epoch}\")\n",
        "            for p in model.cnn.parameters():\n",
        "                p.requires_grad = True\n",
        "\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in loop:\n",
        "            images = batch['image'].to(device)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            img_emb, txt_emb = model(images, input_ids, mask)\n",
        "            loss = contrastive_loss(img_emb, txt_emb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # ------------------------ VALIDATION ------------------------\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device)\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                mask = batch['attention_mask'].to(device)\n",
        "\n",
        "                img_emb, txt_emb = model(images, input_ids, mask)\n",
        "                total_val_loss += contrastive_loss(img_emb, txt_emb).item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # ---------------------- EARLY STOPPING ----------------------\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"Saved NEW BEST MODEL!\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"No improvement ({patience_counter}/{patience})\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early Stopping Triggered.\")\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(\"Training Finished.\")\n",
        "    print(f\"Best model saved at: {save_path}\")\n"
      ],
      "metadata": {
        "id": "31RQrqnr4KWr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING CALL\n",
        "model = DualEncoder(embed_dim=256, freeze_cnn=True).to(device)\n",
        "\n",
        "train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=15,\n",
        "    lr=1e-4,\n",
        "    patience=4,\n",
        "    unfreeze_cnn_epoch=3,\n",
        "    save_path=\"/content/drive/MyDrive/recipe_project/best_model.pt\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0d4e9698a194539bcc18791ad183a27",
            "402819eabfe746a4b867ebcdd8ca5f33",
            "eff65fd586004a86b247c23066cc6ca6",
            "d68da84a89fc44d884d6893ab2038e06",
            "68c6cf0b18f84b0b943b45c72d28569e",
            "11cd62dadbef4613a9139cc960c64cee",
            "c3441f7b4efe4cdf92691f10709e508e",
            "3dd422543e1e44f4a9a9612f46281421",
            "9f7f9a8cf0184912a24f564631a78b02",
            "fd3f3585496d4e3c95a7c6ca1576ad8c",
            "84462cc500464f48a282c6a29c609d8d"
          ]
        },
        "id": "cRFYcojZ4Vzs",
        "outputId": "8598efa8-49a2-4046-c9ca-67c389a29519"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 207MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0d4e9698a194539bcc18791ad183a27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 579/579 [05:45<00:00,  1.68it/s, loss=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/15\n",
            "Train Loss: 3.0264 | Val Loss: 2.6442\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 579/579 [05:37<00:00,  1.71it/s, loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/15\n",
            "Train Loss: 2.6219 | Val Loss: 2.5026\n",
            "Saved NEW BEST MODEL!\n",
            "Unfreezing Text Encoder…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 579/579 [06:31<00:00,  1.48it/s, loss=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/15\n",
            "Train Loss: 2.0122 | Val Loss: 1.7866\n",
            "Saved NEW BEST MODEL!\n",
            "Unfreezing CNN at epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 579/579 [07:23<00:00,  1.31it/s, loss=0.188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/15\n",
            "Train Loss: 1.2486 | Val Loss: 1.2766\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 579/579 [07:16<00:00,  1.33it/s, loss=0.0533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/15\n",
            "Train Loss: 0.6979 | Val Loss: 1.1942\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 579/579 [07:18<00:00,  1.32it/s, loss=0.003]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/15\n",
            "Train Loss: 0.4414 | Val Loss: 1.1176\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|██████████| 579/579 [07:17<00:00,  1.32it/s, loss=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/15\n",
            "Train Loss: 0.2799 | Val Loss: 1.0823\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|██████████| 579/579 [07:16<00:00,  1.33it/s, loss=0.161]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/15\n",
            "Train Loss: 0.2007 | Val Loss: 1.0629\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|██████████| 579/579 [07:14<00:00,  1.33it/s, loss=0.0198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/15\n",
            "Train Loss: 0.1576 | Val Loss: 1.0580\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|██████████| 579/579 [07:16<00:00,  1.33it/s, loss=0.0068]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/15\n",
            "Train Loss: 0.1210 | Val Loss: 1.0549\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|██████████| 579/579 [07:14<00:00,  1.33it/s, loss=0.0281]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/15\n",
            "Train Loss: 0.1006 | Val Loss: 1.0490\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|██████████| 579/579 [07:20<00:00,  1.31it/s, loss=0.00787]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/15\n",
            "Train Loss: 0.0841 | Val Loss: 1.0632\n",
            "No improvement (1/4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|██████████| 579/579 [07:14<00:00,  1.33it/s, loss=0.0854]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/15\n",
            "Train Loss: 0.0716 | Val Loss: 1.0398\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|██████████| 579/579 [07:20<00:00,  1.31it/s, loss=0.000989]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/15\n",
            "Train Loss: 0.0640 | Val Loss: 1.0379\n",
            "Saved NEW BEST MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|██████████| 579/579 [07:21<00:00,  1.31it/s, loss=0.0109]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/15\n",
            "Train Loss: 0.0594 | Val Loss: 1.0409\n",
            "No improvement (1/4)\n",
            "Training Finished.\n",
            "Best model saved at: /content/drive/MyDrive/recipe_project/best_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Testing**"
      ],
      "metadata": {
        "id": "A2hMgV7DkuA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Best Saved Model\n",
        "model = DualEncoder(embed_dim=256, freeze_cnn=False).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/recipe_project/best_model.pt\", map_location=device))\n",
        "model.eval()\n",
        "print(\"Best model loaded for testing.\")\n",
        "\n",
        "\n",
        "# 1. COMPUTE EMBEDDINGS FOR TEST SET\n",
        "image_embeddings = []\n",
        "text_embeddings = []\n",
        "test_recipe_ids = []\n",
        "\n",
        "print(\"Computing embeddings for Test Set\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        images = batch['image'].to(device)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Get embeddings\n",
        "        img_emb, txt_emb = model(images, input_ids, mask)\n",
        "\n",
        "        # Store them on CPU to save GPU memory\n",
        "        image_embeddings.append(img_emb.cpu())\n",
        "        text_embeddings.append(txt_emb.cpu())\n",
        "        test_recipe_ids.extend(batch['recipe_id'])\n",
        "\n",
        "# Concatenate all batches\n",
        "image_embeddings = torch.cat(image_embeddings)\n",
        "text_embeddings = torch.cat(text_embeddings)\n",
        "\n",
        "print(f\"Test Embeddings Shape: {image_embeddings.shape}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. CALCULATE COSINE SIMILARITY MATRIX\n",
        "# ---------------------------------------------------------\n",
        "# Normalize (just to be safe, though model does it too)\n",
        "image_embeddings = F.normalize(image_embeddings, p=2, dim=1)\n",
        "text_embeddings = F.normalize(text_embeddings, p=2, dim=1)\n",
        "\n",
        "# Similarity Matrix: [N_test x N_test]\n",
        "# row i, col j = similarity between Image_i and Text_j\n",
        "similarity_matrix = image_embeddings @ text_embeddings.T\n",
        "\n",
        "# similarity_matrix shape: [N_images, N_texts]\n",
        "\n",
        "\n",
        "# IMAGE → TEXT RETRIEVAL\n",
        "\n",
        "\n",
        "def recall_at_k_i2t(similarity_matrix, k=1):\n",
        "    N = similarity_matrix.shape[0]\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(N):\n",
        "        sims = similarity_matrix[i]\n",
        "        topk_idx = torch.topk(sims, k).indices.tolist()\n",
        "        if i in topk_idx:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / N\n",
        "\n",
        "\n",
        "def median_rank_i2t(similarity_matrix):\n",
        "    N = similarity_matrix.shape[0]\n",
        "    ranks = []\n",
        "\n",
        "    for i in range(N):\n",
        "        sims = similarity_matrix[i]\n",
        "        sorted_idx = torch.argsort(sims, descending=True)\n",
        "        rank = (sorted_idx == i).nonzero(as_tuple=False).item() + 1\n",
        "        ranks.append(rank)\n",
        "\n",
        "    return float(np.median(ranks))\n",
        "\n",
        "\n",
        "\n",
        "# TEXT → IMAGE RETRIEVAL\n",
        "\n",
        "\n",
        "def recall_at_k_t2i(similarity_matrix, k=1):\n",
        "    sim_t2i = similarity_matrix.T\n",
        "    N = sim_t2i.shape[0]\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(N):\n",
        "        sims = sim_t2i[i]\n",
        "        topk_idx = torch.topk(sims, k).indices.tolist()\n",
        "        if i in topk_idx:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / N\n",
        "\n",
        "\n",
        "def median_rank_t2i(similarity_matrix):\n",
        "    sim_t2i = similarity_matrix.T\n",
        "    N = sim_t2i.shape[0]\n",
        "    ranks = []\n",
        "\n",
        "    for i in range(N):\n",
        "        sims = sim_t2i[i]\n",
        "        sorted_idx = torch.argsort(sims, descending=True)\n",
        "        rank = (sorted_idx == i).nonzero(as_tuple=False).item() + 1\n",
        "        ranks.append(rank)\n",
        "\n",
        "    return float(np.median(ranks))\n",
        "\n",
        "\n",
        "\n",
        "# PRINT RESULTS\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"IMAGE → TEXT RETRIEVAL RESULTS\")\n",
        "print(\"==============================\")\n",
        "\n",
        "for k in [1, 5, 10]:\n",
        "    print(f\"Recall@{k}: {recall_at_k_i2t(similarity_matrix, k):.4f}\")\n",
        "\n",
        "print(f\"Median Rank (MedR): {median_rank_i2t(similarity_matrix):.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"TEXT → IMAGE RETRIEVAL RESULTS\")\n",
        "print(\"==============================\")\n",
        "\n",
        "for k in [1, 5, 10]:\n",
        "    print(f\"Recall@{k}: {recall_at_k_t2i(similarity_matrix, k):.4f}\")\n",
        "\n",
        "print(f\"Median Rank (MedR): {median_rank_t2i(similarity_matrix):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQSUQfNgzt_H",
        "outputId": "48897ed2-e1c3-40e5-c5f8-5f4da48efaf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded for testing.\n",
            "Computing embeddings for Test Set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 73/73 [00:36<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Embeddings Shape: torch.Size([2313, 256])\n",
            "\n",
            "==============================\n",
            "IMAGE → TEXT RETRIEVAL RESULTS\n",
            "==============================\n",
            "Recall@1: 0.1271\n",
            "Recall@5: 0.3346\n",
            "Recall@10: 0.4613\n",
            "Median Rank (MedR): 13.00\n",
            "\n",
            "==============================\n",
            "TEXT → IMAGE RETRIEVAL RESULTS\n",
            "==============================\n",
            "Recall@1: 0.1280\n",
            "Recall@5: 0.3411\n",
            "Recall@10: 0.4535\n",
            "Median Rank (MedR): 13.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nutrition (Dietary constraints + health goal) Optimization Layer**"
      ],
      "metadata": {
        "id": "taIGiPAEk2QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. UNZIP NUTRITION DATA\n",
        "# ---------------------------------------------------------\n",
        "NUTRITION_ZIP_PATH = \"/content/drive/MyDrive/recipe_project/archive (2).zip\"\n",
        "NUTRITION_EXTRACT_DIR = \"/content/nutrition_data\"\n",
        "\n",
        "if not os.path.exists(NUTRITION_EXTRACT_DIR):\n",
        "    print(f\"Unzipping {NUTRITION_ZIP_PATH}\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(NUTRITION_ZIP_PATH, 'r') as z:\n",
        "            z.extractall(NUTRITION_EXTRACT_DIR)\n",
        "        print(\"Extraction complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error unzipping: {e}\")\n",
        "else:\n",
        "    print(\"Folder already exists, skipping unzip.\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. FIND ALL DATA CSVs\n",
        "# ---------------------------------------------------------\n",
        "data_csv_files = []\n",
        "for root, dirs, files in os.walk(NUTRITION_EXTRACT_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".csv\") and \"FOOD-DATA\" in file and \"METADATA\" not in file:\n",
        "            data_csv_files.append(os.path.join(root, file))\n",
        "\n",
        "if not data_csv_files:\n",
        "    raise FileNotFoundError(\"No suitable CSV files found!\")\n",
        "\n",
        "print(f\"Found {len(data_csv_files)} data files. Merging...\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. LOAD & MERGE KAGGLE DATA (SMARTER)\n",
        "# ---------------------------------------------------------\n",
        "def get_val(row, possible_cols):\n",
        "    \"\"\"Helper to find the first valid column that exists\"\"\"\n",
        "    for col in possible_cols:\n",
        "        if col in row:\n",
        "            return float(row[col])\n",
        "    return 0.0\n",
        "\n",
        "def load_all_nutrition_files(file_list):\n",
        "    lookup = {}\n",
        "\n",
        "    for csv_path in file_list:\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            # Normalize columns\n",
        "            df.columns = [c.strip().lower().replace(\" \", \"_\").replace(\".\", \"\") for c in df.columns]\n",
        "\n",
        "            # --- Iterate rows ---\n",
        "            for _, row in df.iterrows():\n",
        "                # Get raw name\n",
        "                raw_name = str(row.get('food', '')).lower()\n",
        "                # Clean name: \"Chicken, raw\" -> \"chicken raw\"\n",
        "                clean_name = ''.join(c for c in raw_name if c.isalnum() or c.isspace()).strip()\n",
        "\n",
        "                if not clean_name: continue\n",
        "\n",
        "                # Extract Macros using flexible column names\n",
        "                macros = {\n",
        "                    'calories': get_val(row, ['caloric_value', 'calories', 'energy_kcal']),\n",
        "                    'protein':  get_val(row, ['protein', 'protein_g']),\n",
        "                    'fat':      get_val(row, ['fat', 'total_lipid_fat']),\n",
        "                    'carbs':    get_val(row, ['carbohydrates', 'carbohydrate_by_difference']),\n",
        "                    'sugar':    get_val(row, ['sugars', 'sugars_total'])\n",
        "                }\n",
        "\n",
        "                # --- STRATEGY: SAVE MULTIPLE KEYS ---\n",
        "                # 1. Save the full name: \"chicken raw\"\n",
        "                lookup[clean_name] = macros\n",
        "\n",
        "                # 2. Save the FIRST word: \"chicken\"\n",
        "                # (This fixes your \"Matched 0/3\" error!)\n",
        "                first_word = clean_name.split()[0]\n",
        "                if len(first_word) > 2 and first_word not in lookup:\n",
        "                     lookup[first_word] = macros\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {csv_path}: {e}\")\n",
        "\n",
        "    return lookup\n",
        "\n",
        "nutrition_lookup = load_all_nutrition_files(data_csv_files)\n",
        "print(f\"Successfully loaded {len(nutrition_lookup)} lookup keys.\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. HEURISTIC INGREDIENT PARSER\n",
        "# ---------------------------------------------------------\n",
        "# ---------------------------------------------------------\n",
        "# IMPROVED INGREDIENT PARSER (REPLACE OLD calculate_approx_macros)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def calculate_approx_macros(ingredients_list):\n",
        "    \"\"\"\n",
        "    Improved version:\n",
        "    1. Multi-word matching (e.g., 'chicken breast', 'olive oil')\n",
        "    2. Whole-word matching using regex boundaries\n",
        "    3. Fallback to single-word matching\n",
        "    4. Avoids false positives (egg in eggplant)\n",
        "    \"\"\"\n",
        "\n",
        "    total = {'calories': 0.0, 'protein': 0.0, 'fat': 0.0, 'carbs': 0.0, 'sugar': 0.0}\n",
        "    matched_count = 0\n",
        "\n",
        "    # Pre-clean all nutrition keys for quick search\n",
        "    nutrition_keys = list(nutrition_lookup.keys())\n",
        "\n",
        "    for ingredient in ingredients_list:\n",
        "        ingredient_clean = ingredient.lower()\n",
        "\n",
        "        # -----------------------------------------------\n",
        "        # 1. MULTI-WORD MATCHING (strongest and most accurate)\n",
        "        # -----------------------------------------------\n",
        "        match_found = False\n",
        "\n",
        "        for food_key in nutrition_keys:\n",
        "            # multi-word exact phrase match\n",
        "            pattern = r\"\\b\" + re.escape(food_key) + r\"\\b\"\n",
        "            if re.search(pattern, ingredient_clean):\n",
        "                macros = nutrition_lookup[food_key]\n",
        "                for k in total:\n",
        "                    total[k] += macros[k]\n",
        "                matched_count += 1\n",
        "                match_found = True\n",
        "                break\n",
        "\n",
        "        if match_found:\n",
        "            continue  # skip token matching if phrase match worked\n",
        "\n",
        "        # -----------------------------------------------\n",
        "        # 2. SINGLE-WORD TOKEN MATCHING (fallback)\n",
        "        # -----------------------------------------------\n",
        "        # extract only alphabetical tokens\n",
        "        tokens = re.findall(r\"[a-zA-Z]+\", ingredient_clean)\n",
        "\n",
        "        for token in tokens:\n",
        "            if len(token) <= 2:\n",
        "                continue  # skip useless small words\n",
        "\n",
        "            # whole-word match\n",
        "            if token in nutrition_lookup:\n",
        "                macros = nutrition_lookup[token]\n",
        "                for k in total:\n",
        "                    total[k] += macros[k]\n",
        "                matched_count += 1\n",
        "                match_found = True\n",
        "                break\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3. AVERAGE OVER MATCHED INGREDIENTS\n",
        "    # -----------------------------------------------\n",
        "    if matched_count > 0:\n",
        "        for k in total:\n",
        "            total[k] = round(total[k] / matched_count, 2)\n",
        "    else:\n",
        "        # if nothing matched, return zeros\n",
        "        total = {k: 0.0 for k in total}\n",
        "\n",
        "    return total, matched_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbW7ZDLYP33k",
        "outputId": "d24dcd4e-62de-4d5a-b66e-12ff80f79da4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/drive/MyDrive/recipe_project/archive (2).zip\n",
            "Extraction complete.\n",
            "Found 5 data files. Merging...\n",
            "Successfully loaded 3112 lookup keys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIETARY FILTER\n",
        "\n",
        "import re\n",
        "\n",
        "def check_dietary_compliance(ingredients_list, diet_filter, title=\"\"):\n",
        "    \"\"\"\n",
        "    Enhanced dietary filter:\n",
        "    - Case-insensitive\n",
        "    - Whole-word boundaries (\\bX\\b)\n",
        "    - Multi-word detection\n",
        "    - Checks BOTH ingredients + title\n",
        "    \"\"\"\n",
        "\n",
        "    diet = diet_filter.lower().strip()\n",
        "\n",
        "    # Combine ingredients and title into a unified text blob\n",
        "    text_blob = (title + \" \" + \" \".join(ingredients_list)).lower()\n",
        "\n",
        "    # FOOD CATEGORY LISTS\n",
        "\n",
        "    MEAT = [\n",
        "        \"chicken\", \"chicken breast\", \"ground chicken\",\n",
        "        \"beef\", \"ground beef\", \"steak\", \"veal\",\n",
        "        \"mutton\", \"lamb\", \"goat\",\n",
        "        \"pork\", \"bacon\", \"ham\", \"pepperoni\", \"salami\", \"sirloin\", \"tenderloin\"\n",
        "        \"sausage\", \"turkey\", \"ground chuck\", \"chuck\", \"hen\"\n",
        "    ]\n",
        "\n",
        "    FISH = [\n",
        "        \"fish\", \"seafood\", \"mixed seafood\", \"frozen seafood\",\n",
        "        \"seafood mix\", \"seafood medley\",\n",
        "        \"salmon\", \"tuna\", \"shrimp\", \"prawn\", \"anchovy\", \"cod\",\n",
        "        \"crab\", \"lobster\", \"scallop\", \"mussel\", \"clam\", \"oyster\",\n",
        "        \"squid\", \"octopus\", \"mackerel\", \"trout\", \"snapper\", \"scallops\", \"clams\"\n",
        "    ]\n",
        "\n",
        "    DAIRY = [\n",
        "        \"milk\", \"cheese\", \"butter\", \"yogurt\",\n",
        "        \"cream\", \"parmesan\", \"paneer\", \"ghee\", \"whey\"\n",
        "    ]\n",
        "\n",
        "    EGGS = [\"egg\", \"egg yolk\", \"eggs\"]\n",
        "\n",
        "    HONEY = [\"honey\"]\n",
        "\n",
        "    PORK = [\"pork\", \"bacon\", \"ham\", \"salami\", \"pepperoni\", \"lard\", \"chorizo\"]\n",
        "\n",
        "    ALCOHOL = [\"wine\", \"vodka\", \"rum\", \"beer\", \"whiskey\", \"bourbon\", \"liqueur\"]\n",
        "\n",
        "    GLUTEN = [\"wheat\", \"flour\", \"bread\", \"noodles\", \"pasta\", \"spaghetti\", \"barley\", \"rye\", \"soy sauce\"]\n",
        "\n",
        "    # Helpers for whole-word matching\n",
        "    def contains(words):\n",
        "        for w in words:\n",
        "            pattern = r\"\\b\" + re.escape(w) + r\"\\b\"\n",
        "            if re.search(pattern, text_blob):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    # -----------------------------\n",
        "    # APPLY DIET RULES\n",
        "    # -----------------------------\n",
        "\n",
        "    # Vegan: no meat, fish, dairy, eggs, honey\n",
        "    if diet == \"vegan\":\n",
        "        if contains(MEAT+FISH+DAIRY+EGGS+HONEY):\n",
        "            return False\n",
        "\n",
        "    # Vegetarian: no meat, no fish\n",
        "    if diet == \"vegetarian\":\n",
        "        if contains(MEAT+FISH):\n",
        "            return False\n",
        "\n",
        "    # Pescatarian: no meat, fish allowed\n",
        "    if diet == \"pescatarian\":\n",
        "        if contains(MEAT):\n",
        "            return False\n",
        "\n",
        "    # Halal: no pork, no alcohol\n",
        "    if diet == \"halal\":\n",
        "        if contains(PORK+ALCOHOL):\n",
        "            return False\n",
        "\n",
        "    # Gluten free\n",
        "    if diet == \"gluten free\":\n",
        "        if contains(GLUTEN):\n",
        "            return False\n",
        "\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "T72rZriLQLmy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# BUILD FULL DATABASE INDEX (Train + Val + Test)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. Prepare Data\n",
        "all_recipe_ids = [item['recipe_id'] for item in full_data]\n",
        "full_db_embeddings = []\n",
        "\n",
        "# 2. Create a DataLoader for the Full Dataset (Text Only)\n",
        "# We can reuse the RecipeDataset class but we only need text\n",
        "full_dataset = RecipeDataset(full_data, FINAL_IMG_DIR, val_transform, tokenizer)\n",
        "full_loader = DataLoader(full_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# 3. Compute Embeddings\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(full_loader, desc=\"Indexing Full DB\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Get Text Embeddings from the Model\n",
        "        # We manually call the text branch since we don't have images here\n",
        "        txt_out = model.text_encoder(input_ids=input_ids, attention_mask=mask)\n",
        "        txt_feat = txt_out.last_hidden_state[:, 0, :]\n",
        "        txt_feat = model.text_proj(txt_feat)\n",
        "        txt_feat = F.normalize(txt_feat, p=2, dim=1)\n",
        "\n",
        "        full_db_embeddings.append(txt_feat.cpu())\n",
        "\n",
        "# 4. Concatenate and move to device once, making it a global variable\n",
        "global db_emb\n",
        "db_emb = torch.cat(full_db_embeddings).to(device)\n",
        "print(f\"Full Database Indexed. Shape: {db_emb.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--r92EnQdcY",
        "outputId": "a37ab6bf-27dd-45d4-87bd-def1cf605874"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Indexing Full DB: 100%|██████████| 362/362 [05:23<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Database Indexed. Shape: torch.Size([23127, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# 0. SETUP\n",
        "if 'id_to_entry' not in globals():\n",
        "    id_to_entry = {item['recipe_id']: item for item in full_data}\n",
        "\n",
        "\n",
        "# 1. RETRIEVAL FUNCTION\n",
        "def retrieve_recipe_from_image(image_path, topk=50):\n",
        "    if topk is None: topk = 50\n",
        "    try:\n",
        "        img = PILImage.open(image_path).convert(\"RGB\")\n",
        "        img_t = val_transform(img).unsqueeze(0).to(device)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img_emb, _ = model(images=img_t)\n",
        "        img_emb = F.normalize(img_emb, p=2, dim=1)\n",
        "\n",
        "    sims = (img_emb @ db_emb.T).squeeze(0)\n",
        "\n",
        "    max_k = min(int(topk), len(all_recipe_ids))\n",
        "    top_indices = torch.topk(sims, k=max_k).indices.tolist()\n",
        "\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        rid = all_recipe_ids[idx]\n",
        "        entry = id_to_entry.get(rid)\n",
        "        if entry:\n",
        "            results.append({\n",
        "                \"recipe_id\": rid,\n",
        "                \"similarity\": sims[idx].item(),\n",
        "                \"image_filename\": entry['image_filename'],\n",
        "                \"title\": entry['title']\n",
        "            })\n",
        "    return results"
      ],
      "metadata": {
        "id": "KgD0hlfQQgbd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NUTRITION SCORING\n",
        "\n",
        "# Convert nutrition lookup (all individual foods) into a DataFrame\n",
        "all_macros = pd.DataFrame(nutrition_lookup.values())\n",
        "\n",
        "# Fix column names\n",
        "all_macros = all_macros.rename(columns={\n",
        "    \"sugar\": \"sugar\"\n",
        "})\n",
        "\n",
        "max_cal = all_macros[\"calories\"].max()\n",
        "max_pro = all_macros[\"protein\"].max()\n",
        "max_fat = all_macros[\"fat\"].max()\n",
        "max_carb = all_macros[\"carbs\"].max()\n",
        "max_sug = all_macros[\"sugar\"].max()\n",
        "\n",
        "print(\"Max macro values computed.\")\n",
        "\n",
        "def nutrition_objective_score(macros, objective):\n",
        "    if macros is None:\n",
        "        return 0.0\n",
        "\n",
        "    cal  = macros.get(\"calories\", 0)\n",
        "    pro  = macros.get(\"protein\", 0)\n",
        "    fat  = macros.get(\"fat\", 0)\n",
        "    carb = macros.get(\"carbs\", 0)\n",
        "    sug  = macros.get(\"sugar\", 0)\n",
        "\n",
        "    # Normalization\n",
        "    cal_n  = cal  / (max_cal  + 1e-6)\n",
        "    pro_n  = pro  / (max_pro  + 1e-6)\n",
        "    fat_n  = fat  / (max_fat  + 1e-6)\n",
        "    carb_n = carb / (max_carb + 1e-6)\n",
        "    sug_n  = sug  / (max_sug  + 1e-6)\n",
        "\n",
        "    # Objective scoring\n",
        "    if objective == \"high_protein\":\n",
        "        return pro_n\n",
        "\n",
        "    if objective == \"low_calorie\":\n",
        "        return 1.0 - cal_n\n",
        "\n",
        "    if objective == \"low_fat\":\n",
        "        return 1.0 - fat_n\n",
        "\n",
        "    if objective == \"low_carb\":\n",
        "        return 1.0 - carb_n\n",
        "\n",
        "    if objective == \"sugar_free\":\n",
        "        return 1.0 - sug_n\n",
        "\n",
        "    if objective == \"keto\":\n",
        "        return 0.7*(1-carb_n) + 0.3*(fat_n)\n",
        "\n",
        "    return 0.0\n"
      ],
      "metadata": {
        "id": "ZdYeFYwxSawq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24dd3249-4c88-49b0-ee6d-83ab0ec48062"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max macro values computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. RE-RANKING FUNCTION\n",
        "\n",
        "def rerank_with_constraints(results, diet_type=\"none\", objective=\"none\", alpha=0.5):\n",
        "    final_list = []\n",
        "\n",
        "    # sanitize inputs\n",
        "    diet_type = diet_type.lower()\n",
        "    objective = objective.lower()\n",
        "\n",
        "    for item in results:\n",
        "        rid = item[\"recipe_id\"]\n",
        "        entry = id_to_entry.get(rid)\n",
        "        if entry is None:\n",
        "            continue\n",
        "\n",
        "        # Compute macros\n",
        "        macros, _ = calculate_approx_macros(entry['ingredients'])\n",
        "\n",
        "        # Apply diet filter\n",
        "        if diet_type != \"none\":\n",
        "            if not check_dietary_compliance(entry['ingredients'], diet_type, entry['title']):\n",
        "                continue\n",
        "\n",
        "        # Nutrition score\n",
        "        nut_score = nutrition_objective_score(macros, objective)\n",
        "\n",
        "        # Visual similarity\n",
        "        sim = float(item[\"similarity\"])\n",
        "\n",
        "        # Final score (balanced)\n",
        "        final_score = (alpha * nut_score) + ((1 - alpha) * sim)\n",
        "\n",
        "        enriched = {\n",
        "            \"title\": entry.get(\"title\", \"Unknown\"),\n",
        "            \"image_filename\": entry.get(\"image_filename\", \"\"),\n",
        "            \"ingredients\": entry.get(\"ingredients\", []),\n",
        "            \"instructions\": entry.get(\"instructions\", []),\n",
        "            \"final_score\": final_score,\n",
        "            \"macros\": macros,\n",
        "            \"similarity\": sim\n",
        "        }\n",
        "        final_list.append(enriched)\n",
        "\n",
        "    # Sort descending\n",
        "    final_list.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
        "    return final_list\n"
      ],
      "metadata": {
        "id": "79X3rmhZVNit"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MANUAL TESTING\n",
        "\n",
        "import os\n",
        "\n",
        "test_image_path = os.path.join(PROJECT_ROOT, \"creamy-mushroom-pasta-recipe-8.jpg\")\n",
        "print(f\"Query Image Path: {test_image_path}\")\n",
        "\n",
        "print(\"Step 1: Retrieving Top 50 visual matches...\")\n",
        "raw_results = retrieve_recipe_from_image(test_image_path, topk=200)\n",
        "\n",
        "diet = \"vegetarian\"\n",
        "goal = \"low_calorie\"\n",
        "\n",
        "print(f\"Step 2: Re-ranking with Diet='{diet}' and Goal='{goal}'...\")\n",
        "\n",
        "ranked_results = rerank_with_constraints(\n",
        "    raw_results,\n",
        "    diet_type=diet,\n",
        "    objective=goal,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(f\"TOP 10 RESULTS FOR '{goal.upper()}'\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"{'RANK':<5} | {'SCORE':<8} | {'CAL':<6} | {'PRO':<6} | {'FAT':<6} | {'CARB':<6} | {'SUG':<6} | TITLE\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for i, r in enumerate(ranked_results[:10]):\n",
        "    cal = r[\"macros\"][\"calories\"]\n",
        "    pro = r[\"macros\"][\"protein\"]\n",
        "    fat = r[\"macros\"][\"fat\"]\n",
        "    carb = r[\"macros\"][\"carbs\"]\n",
        "    sug = r[\"macros\"][\"sugar\"]\n",
        "\n",
        "    print(\n",
        "        f\"#{i+1:<4} | {r['final_score']:.4f} | \"\n",
        "        f\"{cal:<6.1f} | {pro:<6.1f} | {fat:<6.1f} | {carb:<6.1f} | {sug:<6.1f} | \"\n",
        "        f\"{r['title'][:40]}\"\n",
        "    )\n",
        "\n",
        "print(\"=\"*90)\n",
        "print(\"ℹNOTE: Final Score = α * NutritionScore + (1-α) * VisualSimilarity\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saovDbfaUATp",
        "outputId": "c20c05ee-d680-42bc-9a2a-659f97dd6f44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Image Path: /content/recipe_project_50k/creamy-mushroom-pasta-recipe-8.jpg\n",
            "Step 1: Retrieving Top 50 visual matches...\n",
            "Step 2: Re-ranking with Diet='vegetarian' and Goal='low_calorie'...\n",
            "\n",
            "==========================================================================================\n",
            "TOP 10 RESULTS FOR 'LOW_CALORIE'\n",
            "==========================================================================================\n",
            "RANK  | SCORE    | CAL    | PRO    | FAT    | CARB   | SUG    | TITLE\n",
            "------------------------------------------------------------------------------------------\n",
            "#1    | 0.9205 | 35.4   | 1.6    | 2.6    | 1.8    | 1.0    | AMIEs PASTA alle ZUCCHINI\n",
            "#2    | 0.9110 | 37.2   | 0.7    | 2.7    | 1.3    | 0.4    | Sig/*ari* Wild mushrooms in garlic, oreg\n",
            "#3    | 0.8977 | 94.4   | 1.8    | 5.1    | 8.6    | 0.6    | Shiitake Pasta\n",
            "#4    | 0.8846 | 117.2  | 3.2    | 2.6    | 18.9   | 2.5    | Spaghetti with Savoy Cabbage, Currants a\n",
            "#5    | 0.8822 | 110.4  | 2.5    | 5.8    | 12.7   | 1.0    | Restaurant Quality Curry Udon Noodles\n",
            "#6    | 0.8821 | 68.9   | 2.1    | 3.3    | 8.0    | 0.6    | Mushrooms and Pasta\n",
            "#7    | 0.8813 | 46.2   | 1.4    | 1.4    | 5.7    | 0.3    | Fettuccine with Brussels Sprouts and Sag\n",
            "#8    | 0.8784 | 54.3   | 1.2    | 2.9    | 5.4    | 1.0    | Pasta Primavera\n",
            "#9    | 0.8771 | 54.0   | 0.2    | 5.5    | 1.2    | 0.6    | Simple Somen Noodles in Hot Soup\n",
            "#10   | 0.8755 | 25.4   | 0.1    | 2.7    | 0.4    | 0.1    | Spaghettini With Garlic, Red Pepper & Ex\n",
            "==========================================================================================\n",
            "ℹNOTE: Final Score = α * NutritionScore + (1-α) * VisualSimilarity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UI-Based Interactive Test\n",
        "\n",
        "import gradio as gr\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 3. FORMATTING RESULT\n",
        "\n",
        "def format_multi_result(recipes):\n",
        "    output_text = \"\"\n",
        "    for i, r in enumerate(recipes[:3]):\n",
        "        m = r['macros']\n",
        "\n",
        "        # Header\n",
        "        output_text += f\"## Result {i+1}: {r['title']}\\n\\n\"\n",
        "\n",
        "        # Stats Block\n",
        "        output_text += f\"**Score:** {r['final_score']:.2f}\\n\\n\"\n",
        "        output_text += f\"**Nutrition (100g):** {m['calories']} cal | **{m['protein']}g Pro** | {m['fat']}g Fat | {m['carbs']}g Carb\\n\\n\"\n",
        "\n",
        "        # Ingredients List\n",
        "        output_text += \"### 🥣 Ingredients\\n\"\n",
        "        # Join with newlines explicitly\n",
        "        ing_formatted = \"\\n\".join([f\"- {ing}\" for ing in r['ingredients'][:8]])\n",
        "        output_text += f\"{ing_formatted}\\n\"\n",
        "\n",
        "        if len(r['ingredients']) > 8:\n",
        "            output_text += f\"- ... ({len(r['ingredients']) - 8} more)\\n\"\n",
        "\n",
        "        # Instructions List\n",
        "        output_text += \"\\n### 📝 Instructions\\n\"\n",
        "        inst_formatted = \"\\n\".join([f\"{j+1}. {inst}\" for j, inst in enumerate(r['instructions'][:5])])\n",
        "        output_text += f\"{inst_formatted}\\n\"\n",
        "\n",
        "        if len(r['instructions']) > 5:\n",
        "            output_text += f\"- ... ({len(r['instructions']) - 5} more steps)\\n\"\n",
        "\n",
        "        output_text += \"\\n---\\n\\n\"\n",
        "    return output_text\n",
        "\n",
        "# GRADIO MAIN\n",
        "def gradio_retrieve(img, diet_type, objective, topk):\n",
        "    if img is None: return \"Please upload an image.\", None\n",
        "\n",
        "    img.save(\"/content/query_image.jpg\")\n",
        "    raw = retrieve_recipe_from_image(\"/content/query_image.jpg\", topk=topk)\n",
        "    final = rerank_with_constraints(raw, diet_type, objective, alpha=0.3)\n",
        "\n",
        "    if not final:\n",
        "        return \"No recipes found.\", None\n",
        "\n",
        "    text_block = format_multi_result(final)\n",
        "\n",
        "    gallery_data = []\n",
        "    for r in final[:3]:\n",
        "        img_path = os.path.join(FINAL_IMG_DIR, r[\"image_filename\"])\n",
        "        if os.path.exists(img_path):\n",
        "            pil_img = PILImage.open(img_path).convert(\"RGB\")\n",
        "            gallery_data.append((pil_img, r[\"title\"])) # Completed the append statement\n",
        "\n",
        "    return text_block, gallery_data # Added the return statement"
      ],
      "metadata": {
        "id": "lnHcC5ptUCa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c0f0d28f",
        "outputId": "de73923a-ba5b-4c92-f2c4-a574ee77e6d7"
      },
      "source": [
        "import gradio as gr\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# FORMATTER\n",
        "# ---------------------------------------------------------\n",
        "def format_multi_result(recipes, topk=3):\n",
        "    output_text = \"\"\n",
        "    for i, r in enumerate(recipes[:topk]):\n",
        "        m = r['macros']\n",
        "\n",
        "        output_text += f\"## Result {i+1}: {r['title']}\\n\\n\"\n",
        "\n",
        "        output_text += f\"**Score:** {r['final_score']:.3f}\\n\\n\"\n",
        "        output_text += (\n",
        "            f\"**Estimated Nutrition:** {m['calories']} cal | \"\n",
        "            f\"**{m['protein']}g Protein** | {m['fat']}g Fat | {m['carbs']}g Carbs\\n\\n\"\n",
        "        )\n",
        "\n",
        "        output_text += \"### 🥣 Ingredients\\n\"\n",
        "        ing_formatted = \"\\n\".join([f\"- {ing}\" for ing in r['ingredients'][:8]])\n",
        "        output_text += ing_formatted + \"\\n\"\n",
        "        if len(r['ingredients']) > 8:\n",
        "            output_text += f\"- ... ({len(r['ingredients']) - 8} more)\\n\"\n",
        "\n",
        "        output_text += \"\\n### 📝 Instructions\\n\"\n",
        "        inst_formatted = \"\\n\".join([f\"{j+1}. {inst}\"\n",
        "                                     for j, inst in enumerate(r['instructions'][:5])])\n",
        "        output_text += inst_formatted + \"\\n\"\n",
        "        if len(r['instructions']) > 5:\n",
        "            output_text += f\"- ... ({len(r['instructions']) - 5} more steps)\\n\"\n",
        "\n",
        "        output_text += \"\\n---\\n\\n\"\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# MAIN GRADIO FUNCTION\n",
        "# ---------------------------------------------------------\n",
        "def gradio_retrieve(img, diet_type, objective, topk):\n",
        "    if img is None:\n",
        "        return \"Please upload an image.\", None\n",
        "\n",
        "    img_path = \"/content/query_image.jpg\"\n",
        "    img.save(img_path)\n",
        "\n",
        "    raw = retrieve_recipe_from_image(img_path, topk=topk)\n",
        "\n",
        "    final = rerank_with_constraints(\n",
        "        raw,\n",
        "        diet_type=diet_type.lower().strip(),   # ★ FIX 1\n",
        "        objective=objective.lower().strip(),   # ★ FIX 2\n",
        "        alpha=0.3\n",
        "    )\n",
        "\n",
        "    if not final:\n",
        "        return \"No recipes found.\", None\n",
        "\n",
        "    text_block = format_multi_result(final, topk=3)\n",
        "\n",
        "    gallery_data = []\n",
        "    for r in final[:3]:\n",
        "        img_path = os.path.join(FINAL_IMG_DIR, r[\"image_filename\"])\n",
        "        if os.path.exists(img_path):\n",
        "            gallery_data.append((PILImage.open(img_path), r[\"title\"]))\n",
        "\n",
        "    return text_block, gallery_data\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# GRADIO UI\n",
        "# ---------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    diet_opts = ['none','vegan','vegetarian','pescatarian','halal','gluten free']  # ★ FIX 3\n",
        "\n",
        "    goal_opts = ['none','high_protein','low_calorie','low_fat','low_carb',\n",
        "                 'sugar_free','keto']  # ★ FIX 4\n",
        "\n",
        "    image_input = gr.Image(type=\"pil\", label=\"Upload an image\")\n",
        "\n",
        "    diet_dropdown = gr.Dropdown(choices=diet_opts, value='none',\n",
        "                                label=\"Dietary Preference\")\n",
        "\n",
        "    objective_dropdown = gr.Dropdown(choices=goal_opts, value='none',\n",
        "                                     label=\"Nutritional Goal\")\n",
        "\n",
        "    topk_slider = gr.Slider(minimum=5, maximum=200, value=50, step=5,\n",
        "                             label=\"Retrieve Top-K Candidates\")  # ★ FIX 5\n",
        "\n",
        "    text_output = gr.Markdown(label=\"Recipe Details\")\n",
        "    gallery_output = gr.Gallery(label=\"Recipe Images\")\n",
        "\n",
        "    demo = gr.Interface(\n",
        "        fn=gradio_retrieve,\n",
        "        inputs=[image_input, diet_dropdown, objective_dropdown, topk_slider],\n",
        "        outputs=[text_output, gallery_output],\n",
        "        title=\"Recipe Retrieval (Image → Recipe + Nutrition + Diet Filters)\",\n",
        "        description=\"Upload a dish image and get matching recipes filtered by diet and nutritional goals.\"\n",
        "    )\n",
        "\n",
        "    demo.launch(debug=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ff49782d92025ef90b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ff49782d92025ef90b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7db231fe68a0 [unset]> is bound to a different event loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3FR1wbvV_QS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
